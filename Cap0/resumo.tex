O controle de diversos graus de liberdade para robôs humanoides é reconhecido como um dos problemas mais difíceis da robótica. Devido a falta de modelos matemáticos, uma abordagem freqüentemente empregada é a de confiar na intuição humana para desenhar manualmente movimentos de \textit{keyframe}, geralmente auxiliados por ferramentas gráficas. Neste trabalho, primeiramente propõe-se alguns métodos baseados em redes neurais para imitar movimentos de \textit{keyframe}. Em seguida, propõe-se uma estrutura de aprendizado que não apenas imita, mas também otimiza o movimento do robô humanóide de acordo com alguma tarefa usando Aprendizado por Reforço Profundo. A técnica desenvolvida não faz nenhuma suposição sobre a implementação subjacente do movimento. A estrutura foi aplicada no domínio do \textit{RoboCup 3D Soccer Simulation} e foi capaz de melhorar a precisão do chute apresentado de 69\% para 92\%, além de melhorar a distância geral do chute.