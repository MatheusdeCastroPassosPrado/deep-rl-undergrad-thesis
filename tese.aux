\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{abnt-url-package=hyperref}
\citation{abnt-emphasize=bf}
\citation{abnt-etal-cite=2}
\citation{abnt-etal-list=0}
\citation{abnt-etal-text=it}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{DBLP:journals/corr/abs-1712-01815}
\citation{DBLP:journals/corr/HeessTSLMWTEWER17}
\citation{cmaesfig}
\citation{mnih2015humanlevel}
\citation{openaifive}
\citation{dejan12}
\citation{tgilharco}
\citation{dabbura2017}
\citation{tgilharco}
\citation{tgilharco}
\citation{sutton1998rli}
\citation{sutton1998rli}
\citation{sutton1998rli}
\citation{davidsilverlec3}
\citation{actorcritic}
\citation{parameternoiseblog}
\citation{tgmuzio}
\gdef \LT@i {\LT@entry 
    {1}{58.4757pt}\LT@entry 
    {1}{270.28549pt}}
\gdef \LT@ii {\LT@entry 
    {2}{216.99408pt}\LT@entry 
    {2}{322.9585pt}}
\citation{DBLP:journals/corr/LuT14}
\citation{DBLP:journals/corr/XiongDHSSSYZ16a}
\citation{DBLP:journals/corr/abs-1712-01815}
\citation{DBLP:journals/corr/HeessTSLMWTEWER17}
\citation{DBLP:journals/corr/abs-1712-01815}
\citation{DBLP:journals/corr/abs-1712-01815}
\citation{DBLP:journals/corr/HeessTSLMWTEWER17}
\citation{DBLP:journals/corr/HeessTSLMWTEWER17}
\citation{10.1007/3-540-64473-3_46}
\citation{simspark2005}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{19}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:intro}{{1}{19}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{19}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contextualization}{19}{section.1.2}}
\citation{AI1110-macalpine}
\citation{LNAI16-MacAlpine}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces AlphaGo Zero, learning model that beat the best players of Go, Chess and Shogi, learning to play without previous human knowledge \cite  {DBLP:journals/corr/abs-1712-01815}.\relax }}{20}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alphazero}{{1.1}{20}{AlphaGo Zero, learning model that beat the best players of Go, Chess and Shogi, learning to play without previous human knowledge \cite {DBLP:journals/corr/abs-1712-01815}.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Locomotion of Agent via Deep Reinforcement Learning \cite  {DBLP:journals/corr/HeessTSLMWTEWER17}.\relax }}{20}{figure.caption.8}}
\newlabel{locomotion}{{1.2}{20}{Locomotion of Agent via Deep Reinforcement Learning \cite {DBLP:journals/corr/HeessTSLMWTEWER17}.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A Snapshot from the RoboCup Soccer 3D Simulation League.\relax }}{20}{figure.caption.9}}
\newlabel{soccer3d}{{1.3}{20}{A Snapshot from the RoboCup Soccer 3D Simulation League.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Objective}{21}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Scope}{21}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Organization of this work}{21}{section.1.5}}
\citation{gouaillier2009}
\citation{simspark}
\citation{AAAI12-MacAlpine}
\citation{kajita2001}
\citation{collins2005}
\citation{muniz2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{23}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:soccer3d}{{2}{23}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The RoboCup Soccer3D Simulation League}{23}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Domain Description}{23}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2} Kick Motion }{23}{subsection.2.1.2}}
\citation{shon2005}
\citation{bartels1987}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Keyframe Movements}{24}{subsection.2.1.3}}
\citation{tgmaximo}
\citation{AAMAS11-urieli}
\citation{Rubinstein:2004:CEM:1014902}
\citation{cmaes}
\citation{cmaesfig}
\citation{cmaesfig}
\citation{AAMAS11-urieli}
\citation{mcalpine2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Optimization Techniques}{25}{subsection.2.1.4}}
\citation{Rummery94on-lineq-learning}
\citation{Watkins:1989}
\citation{mnih2015humanlevel}
\citation{mnih2015humanlevel}
\citation{mnih2015humanlevel}
\citation{alphago}
\citation{alphazero}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Illustration of an actual optimization run with covariance matrix adaptation on a simple two-dimensional problem \cite  {cmaesfig}.\relax }}{26}{figure.caption.10}}
\newlabel{cmaesfigure}{{2.1}{26}{Illustration of an actual optimization run with covariance matrix adaptation on a simple two-dimensional problem \cite {cmaesfig}.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Reinforcement Learning for Control}{26}{section.2.2}}
\citation{mujoco}
\citation{a2c}
\citation{acer}
\citation{ddpg}
\citation{gail}
\citation{her}
\citation{trpo}
\citation{ppoalgorithm}
\citation{DBLP:journals/corr/HeessTSLMWTEWER17}
\citation{peng2018}
\citation{openaifive}
\citation{openaifive}
\citation{openaifive}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Human level control through deep reinforcement learning in atari games \cite  {mnih2015humanlevel}.\relax }}{27}{figure.caption.11}}
\newlabel{dqn}{{2.2}{27}{Human level control through deep reinforcement learning in atari games \cite {mnih2015humanlevel}.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces OpenAI Five network architecture \cite  {openaifive}.\relax }}{28}{figure.caption.12}}
\newlabel{openaifive}{{2.3}{28}{OpenAI Five network architecture \cite {openaifive}.\relax }{figure.caption.12}{}}
\citation{dejan12}
\citation{dejan12}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Learning Background}{29}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:deeplearning}{{3}{29}{Deep Learning Background}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Neural Networks}{29}{section.3.1}}
\newlabel{sec:neural_networks}{{3.1}{29}{Neural Networks}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces An artificial neuron within a feed forward artificial neural network \cite  {dejan12}. \relax }}{29}{figure.caption.13}}
\newlabel{fig:ann}{{3.1}{29}{An artificial neuron within a feed forward artificial neural network \cite {dejan12}. \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}A Neuron}{30}{subsection.3.1.1}}
\newlabel{sec:neuron}{{3.1.1}{30}{A Neuron}{subsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An artificial neuron in detail.\relax }}{30}{figure.caption.14}}
\newlabel{fig:neurondetail}{{3.2}{30}{An artificial neuron in detail.\relax }{figure.caption.14}{}}
\newlabel{eq:neuronequation}{{3.1}{30}{A Neuron}{equation.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Function representation: in (a), we have a sigmoid function where weights vary. In (b), the same sigmoid but only bias varies.\relax }}{31}{figure.caption.15}}
\newlabel{fig:bias}{{3.3}{31}{Function representation: in (a), we have a sigmoid function where weights vary. In (b), the same sigmoid but only bias varies.\relax }{figure.caption.15}{}}
\newlabel{eq:neuronactivation}{{3.2}{31}{A Neuron}{equation.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Neural Network Representation}{31}{subsection.3.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Neural Network representation.\relax }}{31}{figure.caption.16}}
\newlabel{fig:neuralnetworkrepresentation}{{3.4}{31}{Neural Network representation.\relax }{figure.caption.16}{}}
\newlabel{eq:nn_begin}{{3.3}{32}{Neural Network Representation}{equation.3.1.3}{}}
\newlabel{eq:nn_final}{{3.6}{32}{Neural Network Representation}{equation.3.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Vectorization}{32}{subsection.3.1.3}}
\newlabel{sec:vectorization}{{3.1.3}{32}{Vectorization}{subsection.3.1.3}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Activation Functions}{33}{section.3.2}}
\newlabel{sec:activationfunction}{{3.2}{33}{Activation Functions}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Logistic Sigmoid}{33}{subsection.3.2.1}}
\newlabel{eq:sigmoid}{{3.14}{33}{Logistic Sigmoid}{equation.3.2.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Hyperbolic Tangent}{33}{subsection.3.2.2}}
\newlabel{eq:tanh}{{3.15}{33}{Hyperbolic Tangent}{equation.3.2.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Illustration of Sigmoid function.\relax }}{34}{figure.caption.17}}
\newlabel{fig:sigmoid}{{3.5}{34}{Illustration of Sigmoid function.\relax }{figure.caption.17}{}}
\newlabel{eq:tanhsigmoid}{{3.16}{34}{Hyperbolic Tangent}{equation.3.2.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Illustration of $tanh$ function.\relax }}{34}{figure.caption.18}}
\newlabel{fig:tanh}{{3.6}{34}{Illustration of $tanh$ function.\relax }{figure.caption.18}{}}
\citation{Goodfellow-et-al-2016}
\citation{glorot2011a}
\citation{leakyrelu}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Rectified Linear Unit - ReLU}{35}{subsection.3.2.3}}
\newlabel{eq:relu}{{3.17}{35}{Rectified Linear Unit - ReLU}{equation.3.2.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Illustration of ReLU function.\relax }}{35}{figure.caption.19}}
\newlabel{fig:relu}{{3.7}{35}{Illustration of ReLU function.\relax }{figure.caption.19}{}}
\citation{hinton88}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Leaky ReLU}{36}{subsection.3.2.4}}
\newlabel{eq:leakyrelu}{{3.18}{36}{Leaky ReLU}{equation.3.2.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Illustration of leaky ReLU function.\relax }}{36}{figure.caption.20}}
\newlabel{fig:leakyrelu}{{3.8}{36}{Illustration of leaky ReLU function.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Cost Function}{36}{section.3.3}}
\newlabel{eq:cost_function_ml}{{3.19}{36}{Cost Function}{equation.3.3.19}{}}
\citation{tgilharco}
\citation{tgilharco}
\newlabel{eq:errors}{{3.20}{37}{Cost Function}{equation.3.3.20}{}}
\newlabel{eq:cost_function_expectation}{{3.21}{37}{Cost Function}{equation.3.3.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Gradient Descent}{37}{section.3.4}}
\newlabel{gradientdescent}{{3.4}{37}{Gradient Descent}{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Illustration of gradient descent in a two variables optimization \cite  {tgilharco}. \relax }}{38}{figure.caption.21}}
\newlabel{fig:gradientdescent}{{3.9}{38}{Illustration of gradient descent in a two variables optimization \cite {tgilharco}. \relax }{figure.caption.21}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Backpropagation}{39}{section.3.5}}
\newlabel{eq:backprop}{{3.31}{39}{Backpropagation}{equation.3.5.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Optimization Algorithms}{39}{section.3.6}}
\citation{dabbura2017}
\citation{dabbura2017}
\citation{brownlee2017}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Backward computation for a deep neural network\relax }}{40}{algorithm.1}}
\newlabel{alg:backprop}{{1}{40}{Backward computation for a deep neural network\relax }{ALC@unique.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Batch, Mini-batch and Stochastic Gradient Descent}{40}{subsection.3.6.1}}
\newlabel{eq:sgd}{{3.32}{40}{Batch, Mini-batch and Stochastic Gradient Descent}{equation.3.6.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Illustration of Stochastic Gradient Descent optimization. \relax }}{41}{figure.caption.22}}
\newlabel{fig:batchvsstochastic}{{3.10}{41}{Illustration of Stochastic Gradient Descent optimization. \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Illustration of how each variation of Gradient Descent commonly behaves. \cite  {dabbura2017}. \relax }}{41}{figure.caption.23}}
\newlabel{fig:lossfunctiongdvariants}{{3.11}{41}{Illustration of how each variation of Gradient Descent commonly behaves. \cite {dabbura2017}. \relax }{figure.caption.23}{}}
\citation{Sutskever:2013:IIM:3042817.3043064}
\citation{Goodfellow-et-al-2016}
\citation{tgilharco}
\citation{tgilharco}
\citation{hinton2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Momentum}{42}{subsection.3.6.2}}
\newlabel{eq:momentum}{{3.33}{42}{Momentum}{equation.3.6.33}{}}
\newlabel{eq:momentum_b}{{3.34}{42}{Momentum}{equation.3.6.34}{}}
\newlabel{eq:momentumupdate}{{3.37}{42}{Momentum}{equation.3.6.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces  Illustration of how Gradient Descent with Momentum (blue arrows) and without it (black arrows) \cite  {tgilharco}. \relax }}{43}{figure.caption.24}}
\newlabel{fig:momentum}{{3.12}{43}{Illustration of how Gradient Descent with Momentum (blue arrows) and without it (black arrows) \cite {tgilharco}. \relax }{figure.caption.24}{}}
\citation{Goodfellow-et-al-2016}
\citation{adam2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}RMSProp}{44}{subsection.3.6.3}}
\newlabel{eq:rmsprop}{{3.39}{44}{RMSProp}{equation.3.6.39}{}}
\newlabel{eq:rmsprop_b}{{3.40}{44}{RMSProp}{equation.3.6.40}{}}
\newlabel{eq:rmspropupdate}{{3.41}{44}{RMSProp}{equation.3.6.41}{}}
\newlabel{eq:rmspropupdate_b}{{3.43}{44}{RMSProp}{equation.3.6.43}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces RMSProp Algorithm\relax }}{44}{algorithm.2}}
\newlabel{alg:rmsprop}{{2}{44}{RMSProp Algorithm\relax }{ALC@unique.22}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Adam}{45}{subsection.3.6.4}}
\newlabel{eq:adam_1}{{3.44}{45}{Adam}{equation.3.6.44}{}}
\newlabel{eq:adam_2}{{3.45}{45}{Adam}{equation.3.6.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Weights Random Initialization}{45}{section.3.7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Adam Algorithm\relax }}{46}{algorithm.3}}
\newlabel{alg:adam}{{3}{46}{Adam Algorithm\relax }{ALC@unique.44}{}}
\citation{Glorot10}
\citation{Glorot10}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Xavier Initialization}{47}{subsection.3.7.1}}
\newlabel{eq:xavierinitialization}{{3.50}{47}{Xavier Initialization}{equation.3.7.50}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Gradient Descent convergence and learning rate decay}{47}{section.3.8}}
\newlabel{proof:gdconv}{{3.8}{47}{Gradient Descent convergence and learning rate decay}{section.3.8}{}}
\citation{tibshirani2013}
\citation{tgilharco}
\citation{tgilharco}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces  Illustration Gradient Descent divergence for a one variable optimization. \cite  {tgilharco}. \relax }}{48}{figure.caption.25}}
\newlabel{fig:gddivergence}{{3.13}{48}{Illustration Gradient Descent divergence for a one variable optimization. \cite {tgilharco}. \relax }{figure.caption.25}{}}
\citation{sutton1998rli}
\citation{skinner1953science}
\citation{Thorndike173}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Reinforcement Learning Background}{50}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:reinforcementlearning}{{4}{50}{Reinforcement Learning Background}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Concepts of a Reinforcement Learning System}{50}{section.4.1}}
\newlabel{sec:rlconcepts}{{4.1}{50}{Concepts of a Reinforcement Learning System}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Reinforcement Learning System}{51}{section.4.2}}
\newlabel{sec:rlsystem}{{4.2}{51}{Reinforcement Learning System}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Reward}{51}{subsection.4.2.1}}
\newlabel{sec:reward}{{4.2.1}{51}{Reward}{subsection.4.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Reinforcement Learning System.\relax }}{52}{figure.caption.26}}
\newlabel{fig:rlsystem}{{4.1}{52}{Reinforcement Learning System.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}State}{52}{subsection.4.2.2}}
\citation{sutton1998rli}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Policy}{53}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Value Function}{53}{subsection.4.2.4}}
\newlabel{sec:valuefunction}{{4.2.4}{53}{Value Function}{subsection.4.2.4}{}}
\newlabel{eq:valuefunction}{{4.3}{53}{Value Function}{equation.4.2.3}{}}
\citation{sutton1998rli}
\citation{sutton1998rli}
\citation{davidsilverlec2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Model}{54}{subsection.4.2.5}}
\newlabel{eq:modelrl}{{4.4}{54}{Model}{equation.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Markov Decision Process}{54}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Markov State}{54}{subsection.4.3.1}}
\newlabel{sec:markovstate}{{4.3.1}{54}{Markov State}{subsection.4.3.1}{}}
\newlabel{eq:markovstate}{{4.5}{54}{Markov State}{equation.4.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}State Transition Matrix}{55}{subsection.4.3.2}}
\newlabel{sec:statetransition}{{4.3.2}{55}{State Transition Matrix}{subsection.4.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Markov Decision Process}{55}{subsection.4.3.3}}
\citation{davidsilverlec2}
\citation{sutton1998rli}
\citation{sutton1998rli}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The agent\IeC {\textendash }environment interaction in a Markov decision process \cite  {sutton1998rli}.\relax }}{57}{figure.caption.27}}
\newlabel{fig:mdprlsystem}{{4.2}{57}{The agent–environment interaction in a Markov decision process \cite {sutton1998rli}.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}State-Value and Action-Value Function}{57}{subsection.4.3.4}}
\newlabel{def:statevalue}{{8}{57}{State-Value and Action-Value Function}{definition.8}{}}
\newlabel{def:actionvalue}{{9}{57}{State-Value and Action-Value Function}{definition.9}{}}
\citation{sutton1998rli}
\citation{sutton1998rli}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Bellman Equation}{58}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Bellman Expectation Equation}{58}{subsection.4.4.1}}
\newlabel{eq:bellmanbig}{{4.16}{58}{Bellman Expectation Equation}{equation.4.4.16}{}}
\newlabel{eq:bellmanfinal}{{4.17}{58}{Bellman Expectation Equation}{equation.4.4.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Backup diagram for $v_{\pi }$. The white nodes are states, while the black ones are possible actions. Bellman equation average over the actions in a recursive way. \cite  {sutton1998rli}.\relax }}{58}{figure.caption.28}}
\newlabel{fig:bellmaneqtree}{{4.3}{58}{Backup diagram for $v_{\pi }$. The white nodes are states, while the black ones are possible actions. Bellman equation average over the actions in a recursive way. \cite {sutton1998rli}.\relax }{figure.caption.28}{}}
\citation{davidsilverlec2}
\newlabel{eq:bellmanactionvalue}{{4.18}{59}{Bellman Expectation Equation}{equation.4.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Bellman Optimality Equation}{59}{subsection.4.4.2}}
\citation{sutton1998rli}
\citation{sutton1998rli}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Backup diagram in Bellman Optimality Equation for $v_{\pi }$ and $q_{\pi }$. \cite  {sutton1998rli}.\relax }}{60}{figure.caption.29}}
\newlabel{fig:bellmanoptimality}{{4.4}{60}{Backup diagram in Bellman Optimality Equation for $v_{\pi }$ and $q_{\pi }$. \cite {sutton1998rli}.\relax }{figure.caption.29}{}}
\citation{sutton1998rli}
\citation{davidsilverlec3}
\citation{davidsilverlec3}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Exact Solution Methods}{61}{section.4.5}}
\newlabel{sec:exactsolutionmethods}{{4.5}{61}{Exact Solution Methods}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Policy Iteration}{61}{subsection.4.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Policy Iteration algorithm. \cite  {davidsilverlec3}.\relax }}{61}{figure.caption.30}}
\newlabel{fig:policyiteration}{{4.5}{61}{Policy Iteration algorithm. \cite {davidsilverlec3}.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.1}Policy Evaluation}{62}{subsubsection.4.5.1.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Iterative Policy Evaluation\relax }}{62}{algorithm.4}}
\newlabel{alg:policyevaluation}{{4}{62}{Iterative Policy Evaluation\relax }{ALC@unique.50}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.2}Policy Improvement}{62}{subsubsection.4.5.1.2}}
\citation{sutton1998rli}
\citation{sutton1998rli}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1.3}Policy Iteration algorithm}{63}{subsubsection.4.5.1.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Policy Iteration\relax }}{63}{algorithm.5}}
\newlabel{alg:policyiteration}{{5}{63}{Policy Iteration\relax }{ALC@unique.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Value Iteration}{63}{subsection.4.5.2}}
\citation{Rummery94on-lineq-learning}
\citation{Watkins:1989}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Value Iteration\relax }}{64}{algorithm.6}}
\newlabel{alg:valueiteration}{{6}{64}{Value Iteration\relax }{ALC@unique.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Limitations of Exact Solution Methods}{64}{subsection.4.5.3}}
\citation{davidsilverlec6}
\citation{deeprlbootcamplec4}
\citation{davidsilverlec7}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Policy Gradient Methods}{65}{section.4.6}}
\newlabel{sec:pgmethods}{{4.6}{65}{Policy Gradient Methods}{section.4.6}{}}
\citation{sutton1998rli}
\citation{NIPS2010_3922}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Policy Gradient Theorem}{66}{subsection.4.6.1}}
\newlabel{eq:optloss1}{{4.41}{66}{Policy Gradient Theorem}{equation.4.6.41}{}}
\newlabel{eq:gradnodynamics}{{4.48}{67}{Policy Gradient Theorem}{equation.4.6.48}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Actor-Critic Models}{67}{subsection.4.6.2}}
\citation{actorcritic}
\citation{actorcritic}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Actor-Critic model. \cite  {actorcritic}.\relax }}{68}{figure.caption.31}}
\newlabel{fig:actorcritic}{{4.6}{68}{Actor-Critic model. \cite {actorcritic}.\relax }{figure.caption.31}{}}
\citation{DBLP:journals/corr/SchulmanMLJA15}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Advantage Function and GAE Algorithm}{69}{subsection.4.6.3}}
\newlabel{sec:gae}{{4.6.3}{69}{Advantage Function and GAE Algorithm}{subsection.4.6.3}{}}
\newlabel{eq:advgradient}{{4.52}{69}{Advantage Function and GAE Algorithm}{equation.4.6.52}{}}
\newlabel{eq:tderror}{{4.53}{69}{Advantage Function and GAE Algorithm}{equation.4.6.53}{}}
\citation{DBLP:journals/corr/SchulmanMLJA15}
\citation{DBLP:journals/corr/SchulmanMLJA15}
\citation{deeprlbootcamplec5}
\newlabel{eq:gae1}{{4.60}{70}{Advantage Function and GAE Algorithm}{equation.4.6.60}{}}
\newlabel{eq:gae2}{{4.61}{70}{Advantage Function and GAE Algorithm}{equation.4.6.61}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Advanced Policy Gradient Methods}{70}{section.4.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Optimization Loss}{70}{subsection.4.7.1}}
\newlabel{eq:logprobloss}{{4.62}{70}{Optimization Loss}{equation.4.7.62}{}}
\citation{trpo}
\citation{Kakade02approximatelyoptimal}
\citation{trpo}
\citation{Hestenes&Stiefel:1952}
\newlabel{eq:surrloss}{{4.63}{71}{Optimization Loss}{equation.4.7.63}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}Trust Region Policy Optimization -- TRPO}{71}{subsection.4.7.2}}
\newlabel{eq:tr}{{4.64}{71}{Trust Region Policy Optimization -- TRPO}{equation.4.7.64}{}}
\citation{ppoalgorithm}
\citation{ppoalgorithm}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces TRPO Algorithm\relax }}{72}{algorithm.7}}
\newlabel{alg:trpo}{{7}{72}{TRPO Algorithm\relax }{ALC@unique.73}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.3}Proximal Policy Optimization -- PPO}{72}{subsection.4.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.3.1}Clipped Surrogate Loss}{72}{subsubsection.4.7.3.1}}
\newlabel{eq:clipsurrloss}{{4.66}{72}{Clipped Surrogate Loss}{equation.4.7.66}{}}
\citation{a2c}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.3.2}PPO Algorithm}{73}{subsubsection.4.7.3.2}}
\newlabel{eq:finalppoloss}{{4.67}{73}{PPO Algorithm}{equation.4.7.67}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces PPO Algorithm\relax }}{74}{algorithm.8}}
\newlabel{alg:ppo}{{8}{74}{PPO Algorithm\relax }{ALC@unique.81}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Methodology}{75}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:methodology}{{5}{75}{Methodology}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}The Kick Motion Problem}{75}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experimentation Setup}{75}{section.5.2}}
\newlabel{sec:experimentation_setup}{{5.2}{75}{Experimentation Setup}{section.5.2}{}}
\citation{peng2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Reinforcement with Naive Reward - RNR }{76}{subsection.5.2.1}}
\newlabel{naive_reward}{{5.1}{76}{Reinforcement with Naive Reward - RNR}{equation.5.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Reinforcement with Reference Reward - RRR }{76}{subsection.5.2.2}}
\newlabel{complete_reward}{{5.2}{76}{Reinforcement with Reference Reward - RRR}{equation.5.2.2}{}}
\newlabel{diffjoints}{{5.3}{76}{Reinforcement with Reference Reward - RRR}{equation.5.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Reinforcement with Initial State Distribution - RISD}{76}{subsection.5.2.3}}
\newlabel{risd}{{5.2.3}{76}{Reinforcement with Initial State Distribution - RISD}{subsection.5.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Reinforcement with Early Termination - RET}{77}{subsection.5.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Hybrid Learning Model -- HLM}{77}{subsection.5.2.5}}
\citation{muniz2016}
\citation{macalpine2013}
\citation{AAAI12-MacAlpine}
\citation{leakyrelu}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces In the hybrid model, we can ensure the starting point is near of the optimal solution (orange arrow); otherwise, the starting point can be bad and harder to optimize (red arrow).\relax }}{78}{figure.caption.32}}
\newlabel{optimization_intuition}{{5.1}{78}{In the hybrid model, we can ensure the starting point is near of the optimal solution (orange arrow); otherwise, the starting point can be bad and harder to optimize (red arrow).\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Supervised Learning Setup}{78}{section.5.3}}
\newlabel{supervised_learning_setup}{{5.3}{78}{Supervised Learning Setup}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}The Dataset}{78}{subsection.5.3.1}}
\newlabel{AA}{{5.3.1}{78}{The Dataset}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Neural Network Architecture and Hyperparameters}{78}{subsection.5.3.2}}
\citation{AAAI12-MacAlpine}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The architecture of a neural network designed to learn motions.\relax }}{79}{figure.caption.33}}
\newlabel{fig:model_plot}{{5.2}{79}{The architecture of a neural network designed to learn motions.\relax }{figure.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces The Network Summary\relax }}{79}{table.caption.34}}
\newlabel{tab:network_summary}{{5.1}{79}{The Network Summary\relax }{table.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}The Training Procedure}{79}{subsection.5.3.3}}
\citation{adam2014}
\citation{chollet2015keras}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}The Deployment in the Soccer 3D Environment}{80}{subsection.5.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Reinforcement Learning Setup}{80}{section.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Policy Representation}{80}{subsection.5.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1.1}Input Normalization Filter}{80}{subsubsection.5.4.1.1}}
\newlabel{sec:inputnorm}{{5.4.1.1}{80}{Input Normalization Filter}{subsubsection.5.4.1.1}{}}
\citation{Watkins:1989}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Intuition behind input normalization\relax }}{81}{figure.caption.35}}
\newlabel{inputnormfig}{{5.3}{81}{Intuition behind input normalization\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1.2}Neural Network}{81}{subsubsection.5.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Architecture used by pure Reinforcement Learning models.\relax }}{81}{figure.caption.36}}
\newlabel{rlnetwork}{{5.4}{81}{Architecture used by pure Reinforcement Learning models.\relax }{figure.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces The Reinforcement Learning Network Summary\relax }}{81}{table.caption.37}}
\newlabel{tab:rl_network_summary}{{5.2}{81}{The Reinforcement Learning Network Summary\relax }{table.caption.37}{}}
\citation{parameternoiseblog}
\citation{parameternoiseblog}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1.3}Gaussian Action Space Noise}{82}{subsubsection.5.4.1.3}}
\newlabel{gasp}{{5.4.1.3}{82}{Gaussian Action Space Noise}{subsubsection.5.4.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Gaussian noise applied to action space to ensure better exploration in continuous environments. \cite  {parameternoiseblog} \relax }}{82}{figure.caption.38}}
\newlabel{gaussiannoise}{{5.5}{82}{Gaussian noise applied to action space to ensure better exploration in continuous environments. \cite {parameternoiseblog} \relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Task Description}{82}{subsection.5.4.2}}
\citation{tgmuzio}
\citation{tgmuzio}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Task used to learning kick motion.\relax }}{83}{figure.caption.39}}
\newlabel{taskdescription}{{5.6}{83}{Task used to learning kick motion.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Infrastructure}{83}{section.5.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Reinforcement Learning Server}{83}{subsection.5.5.1}}
\newlabel{rlarchitecture}{{5.5.1}{83}{Reinforcement Learning Server}{subsection.5.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1.1}Simulation Server}{83}{subsubsection.5.5.1.1}}
\citation{baselines}
\citation{tensorflow2015-whitepaper}
\citation{grpc}
\citation{protocolbuffers}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Reinforcement Learning Server Architecture. \cite  {tgmuzio} \relax }}{84}{figure.caption.40}}
\newlabel{rlserver}{{5.7}{84}{Reinforcement Learning Server Architecture. \cite {tgmuzio} \relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1.2}Soccer Agent}{84}{subsubsection.5.5.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1.3}Learning Agent}{84}{subsubsection.5.5.1.3}}
\newlabel{learningagent}{{5.5.1.3}{84}{Learning Agent}{subsubsection.5.5.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Neural Network Deployment}{85}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2.1}Import Supervised Model into OpenAI Baselines}{85}{subsubsection.5.5.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {9}{\ignorespaces Import Keras model into Tensorflow\relax }}{85}{algorithm.9}}
\newlabel{importnetworkpseudocode}{{9}{85}{Import Keras model into Tensorflow\relax }{ALC@unique.85}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2.2}Export OpenAI Baselines onto Soccer Agent}{86}{subsubsection.5.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Data flow graph for PPO algorithm. \relax }}{86}{figure.caption.41}}
\newlabel{fig:dataflowgraph}{{5.8}{86}{Data flow graph for PPO algorithm. \relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces  ``Pi" data flow node from PPO. \relax }}{87}{figure.caption.42}}
\newlabel{fig:pigraph}{{5.9}{87}{``Pi" data flow node from PPO. \relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces  Policy data flow graph from Figure \ref  {rlnetwork} \relax }}{87}{figure.caption.43}}
\newlabel{fig:policygraph1}{{5.10}{87}{Policy data flow graph from Figure \ref {rlnetwork} \relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces  Policy data flow graph from Figure \ref  {fig:model_plot} \relax }}{88}{figure.caption.44}}
\newlabel{fig:policygraph2}{{5.11}{88}{Policy data flow graph from Figure \ref {fig:model_plot} \relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Distributed Training}{88}{subsection.5.5.3}}
\newlabel{sec:distributedtraining}{{5.5.3}{88}{Distributed Training}{subsection.5.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3.1}Data Parallelism}{88}{subsubsection.5.5.3.1}}
\citation{heess2017}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces  Master-workers architecture for data parallelism. \relax }}{89}{figure.caption.45}}
\newlabel{fig:master-worker}{{5.12}{89}{Master-workers architecture for data parallelism. \relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3.2}Synchronous vs. Asynchronous Distributed Training}{89}{subsubsection.5.5.3.2}}
\citation{tensorboard}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces  Synchronous and Asynchornous Distributed Training. \relax }}{90}{figure.caption.46}}
\newlabel{fig:distributedtraining}{{5.13}{90}{Synchronous and Asynchornous Distributed Training. \relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Metrics}{90}{subsection.5.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Monitoring via Tensorboard}{91}{subsection.5.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces  Monitoring training metrics with Tensorboard. \relax }}{91}{figure.caption.47}}
\newlabel{fig:tensorboard}{{5.14}{91}{Monitoring training metrics with Tensorboard. \relax }{figure.caption.47}{}}
\citation{inteldevcloud}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results' Analysis and Discussion}{92}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:results}{{6}{92}{Results' Analysis and Discussion}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Distributed Training}{92}{section.6.1}}
\newlabel{scripts}{{1}{92}{}{Hfootnote.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Data collection in best scenario\relax }}{93}{figure.caption.48}}
\newlabel{fig:absdatacollection}{{6.1}{93}{Data collection in best scenario\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Pure Reinforcement Learning methods results}{93}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}RNR}{93}{subsection.6.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces RNR Reward Curve by learning update\relax }}{94}{figure.caption.49}}
\newlabel{fig:rnrreward}{{6.2}{94}{RNR Reward Curve by learning update\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces RNR kick motion sequence.\relax }}{94}{figure.caption.50}}
\newlabel{fig:rnr_kick_sequence}{{6.3}{94}{RNR kick motion sequence.\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}RRR}{94}{subsection.6.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces RRR Reward Curve by learning update\relax }}{95}{figure.caption.51}}
\newlabel{fig:rrrreward}{{6.4}{95}{RRR Reward Curve by learning update\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}RNR+RRR}{95}{subsection.6.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces RNR+RRR Reward Curves by learning update. We trained in two sessions. The blue curve shows the first session and the gray one the second session.\relax }}{96}{figure.caption.52}}
\newlabel{fig:rnrrrrrewardcurve}{{6.5}{96}{RNR+RRR Reward Curves by learning update. We trained in two sessions. The blue curve shows the first session and the gray one the second session.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces RNR+RRR Motion Sequence. In this model, the agent learns to kick with the left leg, as in reference.\relax }}{96}{figure.caption.53}}
\newlabel{fig:rnrrrrreward}{{6.6}{96}{RNR+RRR Motion Sequence. In this model, the agent learns to kick with the left leg, as in reference.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Tradeoff between RNR and RRR models: when RRR is much greater, the models collpases to its model.\relax }}{97}{figure.caption.54}}
\newlabel{fig:rnrrrrtradeoff}{{6.7}{97}{Tradeoff between RNR and RRR models: when RRR is much greater, the models collpases to its model.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}RNR+RRR+RISD}{97}{subsection.6.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces RNR+RRR+RISD learning curve in two sessions of training. The blue curve was the first session and the red one was the second.\relax }}{98}{figure.caption.55}}
\newlabel{fig:rnrrrrrisdcurve}{{6.8}{98}{RNR+RRR+RISD learning curve in two sessions of training. The blue curve was the first session and the red one was the second.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces RNR+RRR+RISD motion sequence.\relax }}{98}{figure.caption.56}}
\newlabel{fig:risdmotionsequence}{{6.9}{98}{RNR+RRR+RISD motion sequence.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}RNR+RRR+RISD+RET}{98}{subsection.6.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Reinforcement ``supervised"}{99}{subsection.6.2.6}}
\newlabel{sec:suprl}{{6.2.6}{99}{Reinforcement ``supervised"}{subsection.6.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces First session of training for reinforcement supervised model.\relax }}{99}{figure.caption.57}}
\newlabel{fig:rlsupcurves}{{6.10}{99}{First session of training for reinforcement supervised model.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Motion sequence from reinforcement supervised learning agent.\relax }}{100}{figure.caption.58}}
\newlabel{fig:rlsupmotionsequence}{{6.11}{100}{Motion sequence from reinforcement supervised learning agent.\relax }{figure.caption.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.7}Other ideas for pure RL techniques}{100}{subsection.6.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Hybrid Learning Models}{101}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Supervised Learning Results}{101}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.1}Training Results}{101}{subsubsection.6.3.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Plots of mean squared error and mean absolute error, during training.\relax }}{101}{figure.caption.59}}
\newlabel{fig:errors}{{6.12}{101}{Plots of mean squared error and mean absolute error, during training.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.2}The Learned Kick Motion}{102}{subsubsection.6.3.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces The kick motion. The first row of figures shows the original kick motion. The second row shows the learned kick motion. Both motions are visually indistinguishable.\relax }}{102}{figure.caption.60}}
\newlabel{fig:motions}{{6.13}{102}{The kick motion. The first row of figures shows the original kick motion. The second row shows the learned kick motion. Both motions are visually indistinguishable.\relax }{figure.caption.60}{}}
\newlabel{footnote_walk}{{2}{102}{}{Hfootnote.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Joint values for comparing original and learned kicks. The neural network was able to fit the joint trajectories with small errors.\relax }}{103}{figure.caption.61}}
\newlabel{fig:kick_joints_curves}{{6.14}{103}{Joint values for comparing original and learned kicks. The neural network was able to fit the joint trajectories with small errors.\relax }{figure.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces The Kick Comparison\relax }}{103}{table.caption.62}}
\newlabel{tab_kicks_statistics}{{6.1}{103}{The Kick Comparison\relax }{table.caption.62}{}}
\citation{macalpine2013}
\citation{macalpine2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.3}The Learned Walk Motion}{104}{subsubsection.6.3.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces Joints positions, during a period of the walking motion for the original walk, and the learned walk and the joints positions effectively attained, during the learned walking motion.\relax }}{104}{figure.caption.63}}
\newlabel{fig:walk_joints_curves}{{6.15}{104}{Joints positions, during a period of the walking motion for the original walk, and the learned walk and the joints positions effectively attained, during the learned walking motion.\relax }{figure.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Walk Comparison - Forward Walk\relax }}{105}{table.caption.64}}
\newlabel{tab_walk}{{6.2}{105}{Walk Comparison - Forward Walk\relax }{table.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces The walking motions comparison. Figure (a) shows our agent in its regular walk, Figure (b) shows the same agent mimicking UT Austin Villa walk, and Figure (c) shows the UT Austin Villa agent itself performing his own walking motion.\relax }}{105}{figure.caption.65}}
\newlabel{fig:walkings}{{6.16}{105}{The walking motions comparison. Figure (a) shows our agent in its regular walk, Figure (b) shows the same agent mimicking UT Austin Villa walk, and Figure (c) shows the UT Austin Villa agent itself performing his own walking motion.\relax }{figure.caption.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.4}Other motions}{105}{subsubsection.6.3.1.4}}
\newlabel{footnote_walk}{{3}{105}{}{Hfootnote.3}{}}
\citation{mcalpine2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}HLM+RNR}{106}{subsection.6.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Final Model: HLM+RNR+RET}{106}{subsection.6.3.3}}
\newlabel{sec:hlmrnrret}{{6.3.3}{106}{Final Model: HLM+RNR+RET}{subsection.6.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces The reward curve from the first session of HLM+RNR+RET model.\relax }}{107}{figure.caption.66}}
\newlabel{fig:hlmretsess1}{{6.17}{107}{The reward curve from the first session of HLM+RNR+RET model.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces HLM+RNR+RET motion sequence after first session of training.\relax }}{107}{figure.caption.67}}
\newlabel{fig:hlmretsess1motseq}{{6.18}{107}{HLM+RNR+RET motion sequence after first session of training.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.19}{\ignorespaces The reward curve from the second session of HLM+RNR+RET model.\relax }}{108}{figure.caption.68}}
\newlabel{fig:hlmretsess2}{{6.19}{108}{The reward curve from the second session of HLM+RNR+RET model.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.20}{\ignorespaces HLM+RNR+RET motion sequence after second training session.\relax }}{108}{figure.caption.69}}
\newlabel{fig:hlmretsess2motseq}{{6.20}{108}{HLM+RNR+RET motion sequence after second training session.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Kick Behavior: Numerical Results}{108}{subsection.6.3.4}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Kick Comparison - General Evaluation\relax }}{109}{table.caption.70}}
\newlabel{tab:finaltest}{{6.3}{109}{Kick Comparison - General Evaluation\relax }{table.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Kick Comparison - Effective Evaluation\relax }}{109}{table.caption.71}}
\newlabel{tab:finaltesteff}{{6.4}{109}{Kick Comparison - Effective Evaluation\relax }{table.caption.71}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions, Recommendations, and Future Works}{110}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:conclusion}{{7}{110}{Conclusions, Recommendations, and Future Works}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Conclusions}{110}{section.7.1}}
\citation{metalearning}
\bibdata{abnt-options,Referencias/referencias}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future Work}{111}{section.7.2}}
\bibcite{tensorflow2015-whitepaper}{Abadi \textit  {et al.} 2015}
\bibciteEXPL{tensorflow2015-whitepaper}{Abadi \textit  {et al.}}
\bibciteIMPL{tensorflow2015-whitepaper}{ABADI \textit  {et al.}}
\bibciteYEAR{tensorflow2015-whitepaper}{2015}
\bibcite{deeprlbootcamplec4}{Abbeel \textit  {et al.} 2017}
\bibciteEXPL{deeprlbootcamplec4}{Abbeel \textit  {et al.}}
\bibciteIMPL{deeprlbootcamplec4}{ABBEEL \textit  {et al.}}
\bibciteYEAR{deeprlbootcamplec4}{2017}
\bibcite{her}{Andrychowicz \textit  {et al.} 2017}
\bibciteEXPL{her}{Andrychowicz \textit  {et al.}}
\bibciteIMPL{her}{ANDRYCHOWICZ \textit  {et al.}}
\bibciteYEAR{her}{2017}
\bibcite{bartels1987}{Bartels \textit  {et al.} 1987}
\bibciteEXPL{bartels1987}{Bartels \textit  {et al.}}
\bibciteIMPL{bartels1987}{BARTELS \textit  {et al.}}
\bibciteYEAR{bartels1987}{1987}
\bibcite{openaifive}{BROCKMAN \textit  {et al.} 2018}
\bibciteEXPL{openaifive}{BROCKMAN \textit  {et al.}}
\bibciteIMPL{openaifive}{BROCKMAN \textit  {et al.}}
\bibciteYEAR{openaifive}{2018}
\bibcite{brownlee2017}{Brownlee 2017}
\bibciteEXPL{brownlee2017}{Brownlee}
\bibciteIMPL{brownlee2017}{BROWNLEE}
\bibciteYEAR{brownlee2017}{2017}
\bibcite{chollet2015keras}{Chollet \textit  {et al.} 2015}
\bibciteEXPL{chollet2015keras}{Chollet \textit  {et al.}}
\bibciteIMPL{chollet2015keras}{CHOLLET \textit  {et al.}}
\bibciteYEAR{chollet2015keras}{2015}
\bibcite{collins2005}{Collins \textit  {et al.} 2005}
\bibciteEXPL{collins2005}{Collins \textit  {et al.}}
\bibciteIMPL{collins2005}{COLLINS \textit  {et al.}}
\bibciteYEAR{collins2005}{2005}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{112}{chapter.8}}
\bibcite{dabbura2017}{Dabbura 2017}
\bibciteEXPL{dabbura2017}{Dabbura}
\bibciteIMPL{dabbura2017}{DABBURA}
\bibciteYEAR{dabbura2017}{2017}
\bibcite{baselines}{Dhariwal \textit  {et al.} 2017}
\bibciteEXPL{baselines}{Dhariwal \textit  {et al.}}
\bibciteIMPL{baselines}{DHARIWAL \textit  {et al.}}
\bibciteYEAR{baselines}{2017}
\bibcite{metalearning}{Duan \textit  {et al.} 2016}
\bibciteEXPL{metalearning}{Duan \textit  {et al.}}
\bibciteIMPL{metalearning}{DUAN \textit  {et al.}}
\bibciteYEAR{metalearning}{2016}
\bibcite{Glorot10}{Glorot e Bengio 2010}
\bibciteEXPL{Glorot10}{Glorot e Bengio}
\bibciteIMPL{Glorot10}{GLOROT; BENGIO}
\bibciteYEAR{Glorot10}{2010}
\bibcite{glorot2011a}{Glorot \textit  {et al.} 2011}
\bibciteEXPL{glorot2011a}{Glorot \textit  {et al.}}
\bibciteIMPL{glorot2011a}{GLOROT \textit  {et al.}}
\bibciteYEAR{glorot2011a}{2011}
\bibcite{Goodfellow-et-al-2016}{Goodfellow \textit  {et al.} 2016}
\bibciteEXPL{Goodfellow-et-al-2016}{Goodfellow \textit  {et al.}}
\bibciteIMPL{Goodfellow-et-al-2016}{GOODFELLOW \textit  {et al.}}
\bibciteYEAR{Goodfellow-et-al-2016}{2016}
\bibcite{gouaillier2009}{Gouaillier \textit  {et al.} 2009}
\bibciteEXPL{gouaillier2009}{Gouaillier \textit  {et al.}}
\bibciteIMPL{gouaillier2009}{GOUAILLIER \textit  {et al.}}
\bibciteYEAR{gouaillier2009}{2009}
\bibcite{grpc}{gRPC 2018}
\bibciteEXPL{grpc}{gRPC}
\bibciteIMPL{grpc}{GRPC}
\bibciteYEAR{grpc}{2018}
\bibcite{cmaes}{Hansen 2016}
\bibciteEXPL{cmaes}{Hansen}
\bibciteIMPL{cmaes}{HANSEN}
\bibciteYEAR{cmaes}{2016}
\bibcite{heess2017}{Heess \textit  {et al.} 2017}
\bibciteEXPL{heess2017}{Heess \textit  {et al.}}
\bibciteIMPL{heess2017}{HEESS \textit  {et al.}}
\bibciteYEAR{heess2017}{2017a}
\bibcite{DBLP:journals/corr/HeessTSLMWTEWER17}{Heess \textit  {et al.} 2017}
\bibciteEXPL{DBLP:journals/corr/HeessTSLMWTEWER17}{Heess \textit  {et al.}}
\bibciteIMPL{DBLP:journals/corr/HeessTSLMWTEWER17}{HEESS \textit  {et al.}}
\bibciteYEAR{DBLP:journals/corr/HeessTSLMWTEWER17}{2017b}
\bibcite{Hestenes&Stiefel:1952}{Hestenes e Stiefel 1952}
\bibciteEXPL{Hestenes&Stiefel:1952}{Hestenes e Stiefel}
\bibciteIMPL{Hestenes&Stiefel:1952}{HESTENES; STIEFEL}
\bibciteYEAR{Hestenes&Stiefel:1952}{1952}
\bibcite{hinton2012}{Hinton e Tieleman 2017}
\bibciteEXPL{hinton2012}{Hinton e Tieleman}
\bibciteIMPL{hinton2012}{HINTON; TIELEMAN}
\bibciteYEAR{hinton2012}{2017}
\bibcite{gail}{Ho e Ermon 2016}
\bibciteEXPL{gail}{Ho e Ermon}
\bibciteIMPL{gail}{HO; ERMON}
\bibciteYEAR{gail}{2016}
\bibcite{inteldevcloud}{Intel 2018}
\bibciteEXPL{inteldevcloud}{Intel}
\bibciteIMPL{inteldevcloud}{INTEL}
\bibciteYEAR{inteldevcloud}{2018}
\bibcite{NIPS2010_3922}{Jie e Abbeel 2010}
\bibciteEXPL{NIPS2010_3922}{Jie e Abbeel}
\bibciteIMPL{NIPS2010_3922}{JIE; ABBEEL}
\bibciteYEAR{NIPS2010_3922}{2010}
\bibcite{kajita2001}{Kajita \textit  {et al.} 2001}
\bibciteEXPL{kajita2001}{Kajita \textit  {et al.}}
\bibciteIMPL{kajita2001}{KAJITA \textit  {et al.}}
\bibciteYEAR{kajita2001}{2001}
\bibcite{Kakade02approximatelyoptimal}{Kakade e Langford 2002}
\bibciteEXPL{Kakade02approximatelyoptimal}{Kakade e Langford}
\bibciteIMPL{Kakade02approximatelyoptimal}{KAKADE; LANGFORD}
\bibciteYEAR{Kakade02approximatelyoptimal}{2002}
\bibcite{cmaesfig}{Khan 2018}
\bibciteEXPL{cmaesfig}{Khan}
\bibciteIMPL{cmaesfig}{KHAN}
\bibciteYEAR{cmaesfig}{2018}
\bibcite{adam2014}{Kingma e Ba 2014}
\bibciteEXPL{adam2014}{Kingma e Ba}
\bibciteIMPL{adam2014}{KINGMA; BA}
\bibciteYEAR{adam2014}{2014}
\bibcite{10.1007/3-540-64473-3_46}{Kitano \textit  {et al.} 1998}
\bibciteEXPL{10.1007/3-540-64473-3_46}{Kitano \textit  {et al.}}
\bibciteIMPL{10.1007/3-540-64473-3_46}{KITANO \textit  {et al.}}
\bibciteYEAR{10.1007/3-540-64473-3_46}{1998}
\bibcite{ddpg}{Lillicrap \textit  {et al.} 2015}
\bibciteEXPL{ddpg}{Lillicrap \textit  {et al.}}
\bibciteIMPL{ddpg}{LILLICRAP \textit  {et al.}}
\bibciteYEAR{ddpg}{2015}
\bibcite{DBLP:journals/corr/LuT14}{Lu e Tang 2014}
\bibciteEXPL{DBLP:journals/corr/LuT14}{Lu e Tang}
\bibciteIMPL{DBLP:journals/corr/LuT14}{LU; TANG}
\bibciteYEAR{DBLP:journals/corr/LuT14}{2014}
\bibcite{AAAI12-MacAlpine}{MacAlpine \textit  {et al.} 2012}
\bibciteEXPL{AAAI12-MacAlpine}{MacAlpine \textit  {et al.}}
\bibciteIMPL{AAAI12-MacAlpine}{MACALPINE \textit  {et al.}}
\bibciteYEAR{AAAI12-MacAlpine}{2012}
\bibcite{macalpine2013}{MacAlpine \textit  {et al.} 2013}
\bibciteEXPL{macalpine2013}{MacAlpine \textit  {et al.}}
\bibciteIMPL{macalpine2013}{MACALPINE \textit  {et al.}}
\bibciteYEAR{macalpine2013}{2013}
\bibcite{LNAI16-MacAlpine}{MacAlpine e Stone 2016}
\bibciteEXPL{LNAI16-MacAlpine}{MacAlpine e Stone}
\bibciteIMPL{LNAI16-MacAlpine}{MACALPINE; STONE}
\bibciteYEAR{LNAI16-MacAlpine}{2016}
\bibcite{mcalpine2017}{MacAlpine e Stone 2017}
\bibciteEXPL{mcalpine2017}{MacAlpine e Stone}
\bibciteIMPL{mcalpine2017}{MACALPINE; STONE}
\bibciteYEAR{mcalpine2017}{2017}
\bibcite{macalpine2017}{MacAlpine e Stone 2018}
\bibciteEXPL{macalpine2017}{MacAlpine e Stone}
\bibciteIMPL{macalpine2017}{MACALPINE; STONE}
\bibciteYEAR{macalpine2017}{2018}
\bibcite{AI1110-macalpine}{MacAlpine \textit  {et al.} 2011}
\bibciteEXPL{AI1110-macalpine}{MacAlpine \textit  {et al.}}
\bibciteIMPL{AI1110-macalpine}{MACALPINE \textit  {et al.}}
\bibciteYEAR{AI1110-macalpine}{2011}
\bibcite{tgilharco}{Magalhaes 2017}
\bibciteEXPL{tgilharco}{Magalhaes}
\bibciteIMPL{tgilharco}{MAGALHAES}
\bibciteYEAR{tgilharco}{2017}
\bibcite{tgmaximo}{Maximo 2012}
\bibciteEXPL{tgmaximo}{Maximo}
\bibciteIMPL{tgmaximo}{MAXIMO}
\bibciteYEAR{tgmaximo}{2012}
\bibcite{a2c}{Mnih \textit  {et al.} 2016}
\bibciteEXPL{a2c}{Mnih \textit  {et al.}}
\bibciteIMPL{a2c}{MNIH \textit  {et al.}}
\bibciteYEAR{a2c}{2016}
\bibcite{mnih2015humanlevel}{Mnih \textit  {et al.} 2015}
\bibciteEXPL{mnih2015humanlevel}{Mnih \textit  {et al.}}
\bibciteIMPL{mnih2015humanlevel}{MNIH \textit  {et al.}}
\bibciteYEAR{mnih2015humanlevel}{2015}
\bibcite{muniz2016}{Muniz \textit  {et al.} 2016}
\bibciteEXPL{muniz2016}{Muniz \textit  {et al.}}
\bibciteIMPL{muniz2016}{MUNIZ \textit  {et al.}}
\bibciteYEAR{muniz2016}{2016}
\bibcite{tgmuzio}{Muzio 2017}
\bibciteEXPL{tgmuzio}{Muzio}
\bibciteIMPL{tgmuzio}{MUZIO}
\bibciteYEAR{tgmuzio}{2017}
\bibcite{simspark2005}{Obst e Rollman 2005}
\bibciteEXPL{simspark2005}{Obst e Rollman}
\bibciteIMPL{simspark2005}{OBST; ROLLMAN}
\bibciteYEAR{simspark2005}{2005}
\bibcite{peng2018}{Peng \textit  {et al.} 2018}
\bibciteEXPL{peng2018}{Peng \textit  {et al.}}
\bibciteIMPL{peng2018}{PENG \textit  {et al.}}
\bibciteYEAR{peng2018}{2018}
\bibcite{parameternoiseblog}{PLAPPERT \textit  {et al.} 2017}
\bibciteEXPL{parameternoiseblog}{PLAPPERT \textit  {et al.}}
\bibciteIMPL{parameternoiseblog}{PLAPPERT \textit  {et al.}}
\bibciteYEAR{parameternoiseblog}{2017}
\bibcite{Rubinstein:2004:CEM:1014902}{Rubinstein e Kroese 2004}
\bibciteEXPL{Rubinstein:2004:CEM:1014902}{Rubinstein e Kroese}
\bibciteIMPL{Rubinstein:2004:CEM:1014902}{RUBINSTEIN; KROESE}
\bibciteYEAR{Rubinstein:2004:CEM:1014902}{2004}
\bibcite{hinton88}{Rumelhart \textit  {et al.} 1988}
\bibciteEXPL{hinton88}{Rumelhart \textit  {et al.}}
\bibciteIMPL{hinton88}{RUMELHART \textit  {et al.}}
\bibciteYEAR{hinton88}{1988}
\bibcite{Rummery94on-lineq-learning}{Rummery e Niranjan 1994}
\bibciteEXPL{Rummery94on-lineq-learning}{Rummery e Niranjan}
\bibciteIMPL{Rummery94on-lineq-learning}{RUMMERY; NIRANJAN}
\bibciteYEAR{Rummery94on-lineq-learning}{1994}
\bibcite{deeprlbootcamplec5}{Schulman 2017}
\bibciteEXPL{deeprlbootcamplec5}{Schulman}
\bibciteIMPL{deeprlbootcamplec5}{SCHULMAN}
\bibciteYEAR{deeprlbootcamplec5}{2017}
\bibcite{trpo}{Schulman \textit  {et al.} 2015}
\bibciteEXPL{trpo}{Schulman \textit  {et al.}}
\bibciteIMPL{trpo}{SCHULMAN \textit  {et al.}}
\bibciteYEAR{trpo}{2015a}
\bibcite{DBLP:journals/corr/SchulmanMLJA15}{Schulman \textit  {et al.} 2015}
\bibciteEXPL{DBLP:journals/corr/SchulmanMLJA15}{Schulman \textit  {et al.}}
\bibciteIMPL{DBLP:journals/corr/SchulmanMLJA15}{SCHULMAN \textit  {et al.}}
\bibciteYEAR{DBLP:journals/corr/SchulmanMLJA15}{2015b}
\bibcite{ppoalgorithm}{Schulman \textit  {et al.} 2017}
\bibciteEXPL{ppoalgorithm}{Schulman \textit  {et al.}}
\bibciteIMPL{ppoalgorithm}{SCHULMAN \textit  {et al.}}
\bibciteYEAR{ppoalgorithm}{2017}
\bibcite{shon2005}{Shon \textit  {et al.} 2005}
\bibciteEXPL{shon2005}{Shon \textit  {et al.}}
\bibciteIMPL{shon2005}{SHON \textit  {et al.}}
\bibciteYEAR{shon2005}{2005}
\bibcite{davidsilverlec2}{Silver 2015}
\bibciteEXPL{davidsilverlec2}{Silver}
\bibciteIMPL{davidsilverlec2}{SILVER}
\bibciteYEAR{davidsilverlec2}{2015a}
\bibcite{davidsilverlec3}{Silver 2015}
\bibciteEXPL{davidsilverlec3}{Silver}
\bibciteIMPL{davidsilverlec3}{SILVER}
\bibciteYEAR{davidsilverlec3}{2015b}
\bibcite{davidsilverlec7}{Silver 2015}
\bibciteEXPL{davidsilverlec7}{Silver}
\bibciteIMPL{davidsilverlec7}{SILVER}
\bibciteYEAR{davidsilverlec7}{2015c}
\bibcite{davidsilverlec6}{Silver 2015}
\bibciteEXPL{davidsilverlec6}{Silver}
\bibciteIMPL{davidsilverlec6}{SILVER}
\bibciteYEAR{davidsilverlec6}{2015d}
\bibcite{DBLP:journals/corr/abs-1712-01815}{Silver \textit  {et al.} 2017}
\bibciteEXPL{DBLP:journals/corr/abs-1712-01815}{Silver \textit  {et al.}}
\bibciteIMPL{DBLP:journals/corr/abs-1712-01815}{SILVER \textit  {et al.}}
\bibciteYEAR{DBLP:journals/corr/abs-1712-01815}{2017a}
\bibcite{alphazero}{Silver \textit  {et al.} 2017}
\bibciteEXPL{alphazero}{Silver \textit  {et al.}}
\bibciteIMPL{alphazero}{SILVER \textit  {et al.}}
\bibciteYEAR{alphazero}{2017b}
\bibcite{alphago}{Silver \textit  {et al.} 2017}
\bibciteEXPL{alphago}{Silver \textit  {et al.}}
\bibciteIMPL{alphago}{SILVER \textit  {et al.}}
\bibciteYEAR{alphago}{2017c}
\bibcite{skinner1953science}{Skinner 1953}
\bibciteEXPL{skinner1953science}{Skinner}
\bibciteIMPL{skinner1953science}{SKINNER}
\bibciteYEAR{skinner1953science}{1953}
\bibcite{Sutskever:2013:IIM:3042817.3043064}{Sutskever \textit  {et al.} 2013}
\bibciteEXPL{Sutskever:2013:IIM:3042817.3043064}{Sutskever \textit  {et al.}}
\bibciteIMPL{Sutskever:2013:IIM:3042817.3043064}{SUTSKEVER \textit  {et al.}}
\bibciteYEAR{Sutskever:2013:IIM:3042817.3043064}{2013}
\bibcite{sutton1998rli}{Sutton e Barto 1998}
\bibciteEXPL{sutton1998rli}{Sutton e Barto}
\bibciteIMPL{sutton1998rli}{SUTTON; BARTO}
\bibciteYEAR{sutton1998rli}{1998}
\bibcite{dejan12}{Tanikic e Despotovic 2012}
\bibciteEXPL{dejan12}{Tanikic e Despotovic}
\bibciteIMPL{dejan12}{TANIKIC; DESPOTOVIC}
\bibciteYEAR{dejan12}{2012}
\bibcite{Thorndike173}{Thorndike 1933}
\bibciteEXPL{Thorndike173}{Thorndike}
\bibciteIMPL{Thorndike173}{THORNDIKE}
\bibciteYEAR{Thorndike173}{1933}
\bibcite{tibshirani2013}{Tibshirani 2013}
\bibciteEXPL{tibshirani2013}{Tibshirani}
\bibciteIMPL{tibshirani2013}{TIBSHIRANI}
\bibciteYEAR{tibshirani2013}{2013}
\bibcite{mujoco}{Todorov \textit  {et al.} 2012}
\bibciteEXPL{mujoco}{Todorov \textit  {et al.}}
\bibciteIMPL{mujoco}{TODOROV \textit  {et al.}}
\bibciteYEAR{mujoco}{2012}
\bibcite{AAMAS11-urieli}{Urieli \textit  {et al.} 2011}
\bibciteEXPL{AAMAS11-urieli}{Urieli \textit  {et al.}}
\bibciteIMPL{AAMAS11-urieli}{URIELI \textit  {et al.}}
\bibciteYEAR{AAMAS11-urieli}{2011}
\bibcite{protocolbuffers}{Varda 2008}
\bibciteEXPL{protocolbuffers}{Varda}
\bibciteIMPL{protocolbuffers}{VARDA}
\bibciteYEAR{protocolbuffers}{2008}
\bibcite{acer}{Wang \textit  {et al.} 2016}
\bibciteEXPL{acer}{Wang \textit  {et al.}}
\bibciteIMPL{acer}{WANG \textit  {et al.}}
\bibciteYEAR{acer}{2016}
\bibcite{Watkins:1989}{Watkins 1989}
\bibciteEXPL{Watkins:1989}{Watkins}
\bibciteIMPL{Watkins:1989}{WATKINS}
\bibciteYEAR{Watkins:1989}{1989}
\bibcite{tensorboard}{Wongsuphasawat \textit  {et al.} 2017}
\bibciteEXPL{tensorboard}{Wongsuphasawat \textit  {et al.}}
\bibciteIMPL{tensorboard}{WONGSUPHASAWAT \textit  {et al.}}
\bibciteYEAR{tensorboard}{2017}
\bibcite{DBLP:journals/corr/XiongDHSSSYZ16a}{Xiong \textit  {et al.} 2016}
\bibciteEXPL{DBLP:journals/corr/XiongDHSSSYZ16a}{Xiong \textit  {et al.}}
\bibciteIMPL{DBLP:journals/corr/XiongDHSSSYZ16a}{XIONG \textit  {et al.}}
\bibciteYEAR{DBLP:journals/corr/XiongDHSSSYZ16a}{2016}
\bibcite{leakyrelu}{Xu \textit  {et al.} 2015}
\bibciteEXPL{leakyrelu}{Xu \textit  {et al.}}
\bibciteIMPL{leakyrelu}{XU \textit  {et al.}}
\bibciteYEAR{leakyrelu}{2015}
\bibcite{actorcritic}{Xu \textit  {et al.} 2007}
\bibciteEXPL{actorcritic}{Xu \textit  {et al.}}
\bibciteIMPL{actorcritic}{XU \textit  {et al.}}
\bibciteYEAR{actorcritic}{2007}
\bibcite{simspark}{Xu e Vatankhah 2014}
\bibciteEXPL{simspark}{Xu e Vatankhah}
\bibciteIMPL{simspark}{XU; VATANKHAH}
\bibciteYEAR{simspark}{2014}
\newlabel{LastPage}{{}{119}{}{page.119}{}}
\xdef\lastpage@lastpage{119}
\xdef\lastpage@lastpageHy{119}
\bibstyle{abnt-alf}
